{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4aa5777-e805-4b0e-b56f-1cfa2fb3f4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c9e1e007-dae2-4849-92ef-aa2fe798acdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "12ee9796-7969-4986-a706-57facaf751fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd376014-cc55-456f-a320-fa837a89e336",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9a476cff-cfbd-42cc-9ad8-c948c04049b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 16\n",
    "SUFFIX = '-vanillaCNN'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de98b67-ee0f-4833-9bec-4061124252c0",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "957b1e88-387f-4a1d-ba73-96db987bf0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMG_DIR = 'output/images'\n",
    "RUN_NAME_SUFFIX = '-preprocessed2' # ''\n",
    "IMG_DIR = 'output/images_preprocessed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d120a693-65c9-4fae-b6c4-af192d6b1fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! du -h {IMG_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4d023c88-0278-420c-9064-02ccdfefaa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from era_data import TabletPeriodDataset, get_IDS\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cfb946aa-1523-41e8-ac4e-9a779fcf81fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97640"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDS = get_IDS(IMG_DIR=IMG_DIR)\n",
    "len(IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7dbe645e-e8f9-4453-8c4b-6a131fb58e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'period_clf_bs16_lr0.001_3epochs-vanillaCNN-97640_samples-preprocessed2'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VERSION_NAME = f'period_clf_bs{BATCH_SIZE}_lr{LR}_{EPOCHS}epochs{SUFFIX}-{len(IDS)}_samples{RUN_NAME_SUFFIX}'\n",
    "VERSION_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b495d3f7-ebde-4107-926e-8da274a8b9d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97140, 500)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids, test_ids = train_test_split(IDS, test_size=500, random_state=0)\n",
    "len(train_ids), len(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "93883080-580f-453c-8493-37956bf4d88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering 97640 IDS down to provided 97140...\n",
      "Filtering 97640 IDS down to provided 500...\n"
     ]
    }
   ],
   "source": [
    "ds_train = TabletPeriodDataset(IDS=train_ids, IMG_DIR=IMG_DIR)\n",
    "ds_test = TabletPeriodDataset(IDS=test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0ee03f0b-8892-49f5-885f-2a1d21040e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def collate_fn(batch):\n",
    "    unsqueezed_data = []\n",
    "    labels = []\n",
    "\n",
    "    for sample in batch:\n",
    "        \n",
    "        if isinstance(sample[0], np.ndarray):\n",
    "            img = Image.fromarray(sample[0])\n",
    "        else:\n",
    "            img = sample[0] \n",
    "\n",
    "        # Resize the image\n",
    "        img_resized = img.resize((178, 218), Image.NEAREST)\n",
    "\n",
    "        # Convert the resized PIL image to a tensor and unsqueeze to add a channel dimension\n",
    "        img_tensor = torch.unsqueeze(torch.tensor(np.array(img_resized), dtype=torch.float32), 0)\n",
    "\n",
    "        unsqueezed_data.append(img_tensor)\n",
    "        labels.append(sample[1])\n",
    "\n",
    "    # Stack all the image tensors and labels together\n",
    "    data_tensor = torch.stack(unsqueezed_data, dim=0)\n",
    "    labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    return data_tensor, labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3ea25644-ad8f-4ef9-aba6-501d5bf0df32",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(ds_train, batch_size=BATCH_SIZE,collate_fn=collate_fn, shuffle=True, num_workers=4)\n",
    "dl_test = DataLoader(ds_test, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "85719f9d-4eaa-4250-87b5-451d77c2d032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model IDs so we can keep track of what data it was trained on\n",
    "pd.Series(train_ids).to_csv(f'output/clf_ids/period-train-{VERSION_NAME}.csv', index=False, header=None)\n",
    "pd.Series(test_ids).to_csv(f'output/clf_ids/period-test-{VERSION_NAME}.csv', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e4576f69-0f93-4da4-b497-7109a2f6d464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(TabletPeriodDataset.PERIOD_INDICES) + 2\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "720c10e1-1a76-43de-b03d-5dd236843d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "class SimpleCNN(pl.LightningModule):\n",
    "    def __init__(self, num_classes, learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1) \n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.fc1 = nn.Linear(2383104, 128)  \n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        return {'test_logits': logits, 'test_y': y}\n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        # Concatenate all logits and labels gathered from each test_step\n",
    "        logits = torch.cat([x['test_logits'] for x in outputs], dim=0)\n",
    "        labels = torch.cat([x['test_y'] for x in outputs], dim=0)\n",
    "        self.log('test_logits', logits)\n",
    "        self.log('test_labels', labels)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "426d77a0-c22d-4ed8-88d2-09edcc58a4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN(num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e8533841-7a7b-4cd4-b7b4-ed876628914f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kapond/.conda/envs/dani_torch/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/kapond/.conda/envs/dani_torch/lib/python3.11/s ...\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "logger = pl.loggers.TensorBoardLogger(\n",
    "    save_dir='.',\n",
    "    name='lightning_logs',\n",
    "    version=VERSION_NAME\n",
    ")\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=EPOCHS,\n",
    "    accelerator='gpu',\n",
    "    devices='auto',\n",
    "    callbacks=[lr_monitor],\n",
    "    logger=logger\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "94aeab05-eb14-426c-821b-d07cfc26b4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs to: period_clf_bs16_lr0.001_3epochs-vanillaCNN-97640_samples-preprocessed2\n"
     ]
    }
   ],
   "source": [
    "print('Logs to:', VERSION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fa017983-16b3-4074-a969-e028d1236807",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kapond/.conda/envs/dani_torch/lib/python3.11/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: UserWarning: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "  rank_zero_warn(\"You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\")\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | conv1 | Conv2d | 320   \n",
      "1 | conv2 | Conv2d | 18.5 K\n",
      "2 | fc1   | Linear | 305 M \n",
      "3 | fc2   | Linear | 3.1 K \n",
      "---------------------------------\n",
      "305 M     Trainable params\n",
      "0         Non-trainable params\n",
      "305 M     Total params\n",
      "1,220.237 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1877820fce124467bb20b143c7eafc71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dl_train, dl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7398335c-a0d5-4ac4-853b-c38cdea6257e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b125770-c7ef-43bc-8f7d-08476377a0d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "67f52e35-f29f-469c-9856-ba01c9fc0d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "addaf5d2-4317-4d4a-986b-9ec6b2887622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from itertools import islice\n",
    "\n",
    "\n",
    "def dl2data(dl, MAX_N=None, device='cuda'):\n",
    "    logits = []\n",
    "    y_true = []  # This will hold the period indices\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():\n",
    "        gen = tqdm(islice(dl, MAX_N), total=(MAX_N if MAX_N is not None else len(dl)))\n",
    "        for img, period_index in gen:\n",
    "            try:\n",
    "                y_true.append(period_index.cpu().numpy())  # Append period indices\n",
    "                logits.append(model(img.to(device)).cpu().numpy())  # Process the image through the model\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing batch: {e}\")\n",
    "    y_true = np.hstack(y_true)\n",
    "    logits = np.vstack(logits)\n",
    "\n",
    "    return logits, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f950d48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 1/32 [00:00<00:04,  7.48it/s]\u001b[A\n",
      " 28%|██▊       | 9/32 [00:00<00:00, 42.19it/s]\u001b[A\n",
      " 50%|█████     | 16/32 [00:00<00:00, 48.30it/s]\u001b[A\n",
      "100%|██████████| 32/32 [00:00<00:00, 38.35it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "logits, y_true = dl2data(dl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d95ae64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500,), (500, 24))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.shape, logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "266e0f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy \n",
    "\n",
    "y_pred = logits.argmax(axis=-1)\n",
    "y_prob = scipy.special.softmax(logits, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3bfcd9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500,), (500, 24))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape, y_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d103f5df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.634"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred == y_true).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5fef70ef-3471-4eb9-8fdf-3e027f3b4f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.80      0.81      0.80       140\n",
      "           2       0.84      0.80      0.82       109\n",
      "           3       0.51      0.57      0.54        91\n",
      "           4       0.40      0.29      0.33        35\n",
      "           5       0.22      0.35      0.27        23\n",
      "           6       0.69      0.47      0.56        19\n",
      "           7       0.31      0.40      0.35        10\n",
      "           8       0.50      0.11      0.18         9\n",
      "           9       0.80      0.53      0.64        15\n",
      "          10       0.15      0.38      0.21         8\n",
      "          11       0.62      0.67      0.64        12\n",
      "          12       0.75      0.43      0.55         7\n",
      "          13       0.80      0.67      0.73         6\n",
      "          14       0.60      0.60      0.60         5\n",
      "          15       0.25      0.33      0.29         3\n",
      "          16       1.00      0.50      0.67         2\n",
      "          17       1.00      1.00      1.00         1\n",
      "          19       1.00      1.00      1.00         1\n",
      "          20       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.63       500\n",
      "   macro avg       0.56      0.49      0.51       500\n",
      "weighted avg       0.66      0.63      0.64       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kapond/.conda/envs/dani_torch/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kapond/.conda/envs/dani_torch/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kapond/.conda/envs/dani_torch/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "55de57f5-ea49-4a38-96af-f55846238ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EARLY_BRONZE = {\n",
    "    'Old Akkadian', 'Ur III',\n",
    "    'ED IIIb', 'Uruk III',\n",
    "    'Proto-Elamite', 'Lagash II',\n",
    "    'Ebla', 'ED IIIa', 'ED I-II',\n",
    "    'Uruk IV', 'Linear Elamite',\n",
    "    'Harappan'\n",
    "    \n",
    "}\n",
    "MID_LATE_BRONZE = {\n",
    "    'Early Old Babylonian',\n",
    "    'Old Babylonian', 'Old Assyrian',\n",
    "    'Middle Babylonian', 'Middle Assyrian',\n",
    "    'Middle Elamite', 'Middle Hittite'\n",
    "}\n",
    "IRON = {\n",
    "    'Neo-Babylonian', 'Neo-Assyrian',\n",
    "    'Achaemenid', 'Hellenistic',\n",
    "    'Neo-Elamite'\n",
    "}\n",
    "ERA_MAP = {\n",
    "    **{K: 'EB' for K in EARLY_BRONZE},\n",
    "    **{K: 'MLB' for K in MID_LATE_BRONZE},\n",
    "    **{K: 'I' for K in IRON},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f9348ded-4f7d-41fb-9093-cec6059eea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain(period):\n",
    "    return f'{period} ({ERA_MAP.get(period, \"?\")})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f5ef2f22-f998-4d41-84c6-52b9db3da15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2period = {v: k for k, v in TabletPeriodDataset.PERIOD_INDICES.items()}\n",
    "idx2period[0] = 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9f2964b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common labels: (9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 'Ur III (EB)'),\n",
       " (2, 'Neo-Assyrian (I)'),\n",
       " (3, 'Old Babylonian (MLB)'),\n",
       " (4, 'Middle Babylonian (MLB)'),\n",
       " (5, 'Neo-Babylonian (I)'),\n",
       " (6, 'Old Akkadian (EB)'),\n",
       " (7, 'Achaemenid (I)'),\n",
       " (9, 'ED IIIb (EB)'),\n",
       " (11, 'Old Assyrian (MLB)')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's just use classes with support >=10, everything else goes to 0: other\n",
    "COMMON_LABELS = list({k for k, v in Counter(y_true).items() if v >= 10})\n",
    "print(f'Common labels: ({len(COMMON_LABELS)})')\n",
    "[(i, explain(idx2period[i])) for i in COMMON_LABELS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "950685c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.092 changed to \"other\"\n"
     ]
    }
   ],
   "source": [
    "y_true_c = y_true.copy()\n",
    "y_true_c[~np.isin(y_true, COMMON_LABELS)] = 0\n",
    "print((~np.isin(y_true, COMMON_LABELS)).mean(), 'changed to \"other\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "50b1e78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.086 changed to \"other\"\n"
     ]
    }
   ],
   "source": [
    "y_pred_c = y_pred.copy()\n",
    "y_pred_c[~np.isin(y_pred, COMMON_LABELS)] = 0\n",
    "print((~np.isin(y_pred, COMMON_LABELS)).mean(), 'changed to \"other\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f93f3532",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 9, 11]\n",
      "['other (?)', 'Ur III (EB)', 'Neo-Assyrian (I)', 'Old Babylonian (MLB)', 'Middle Babylonian (MLB)', 'Neo-Babylonian (I)', 'Old Akkadian (EB)', 'Achaemenid (I)', 'ED IIIb (EB)', 'Old Assyrian (MLB)']\n"
     ]
    }
   ],
   "source": [
    "indices_c = list(set(y_true_c) | set(y_pred_c))\n",
    "print(len(indices_c))\n",
    "print(indices_c)\n",
    "PERIOD_LABELS_C = [explain(idx2period[i]) for i in indices_c]\n",
    "print(PERIOD_LABELS_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "807b7258",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "              other (?)       0.53      0.50      0.52        46\n",
      "            Ur III (EB)       0.80      0.81      0.80       140\n",
      "       Neo-Assyrian (I)       0.84      0.80      0.82       109\n",
      "   Old Babylonian (MLB)       0.51      0.57      0.54        91\n",
      "Middle Babylonian (MLB)       0.40      0.29      0.33        35\n",
      "     Neo-Babylonian (I)       0.22      0.35      0.27        23\n",
      "      Old Akkadian (EB)       0.69      0.47      0.56        19\n",
      "         Achaemenid (I)       0.31      0.40      0.35        10\n",
      "           ED IIIb (EB)       0.80      0.53      0.64        15\n",
      "     Old Assyrian (MLB)       0.62      0.67      0.64        12\n",
      "\n",
      "               accuracy                           0.64       500\n",
      "              macro avg       0.57      0.54      0.55       500\n",
      "           weighted avg       0.66      0.64      0.65       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true_c, y_pred_c, target_names=PERIOD_LABELS_C))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dani_torch",
   "language": "python",
   "name": "dani_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
