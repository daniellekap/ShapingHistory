{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d762a5de-7e90-4121-8d1f-e90b53ce7763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import display, clear_output\n",
    "from ipywidgets import widgets, Output\n",
    "import torch\n",
    "from PIL import Image\n",
    "from era_data import TabletPeriodDataset, get_IDS\n",
    "from VAE_model_tablets_class import VAE\n",
    "import pandas as pd\n",
    "from visualization_funcs import generate_image_from_VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85260679-273f-4f47-b213-e698cfb88400",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# IMG_DIR = 'output/images'\n",
    "RUN_NAME_SUFFIX = '-masked_w_classification_loss' # ''\n",
    "IMG_DIR = 'output/images_preprocessed'\n",
    "LR = 5e-5\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 16\n",
    "SUFFIX = '-resnet50'\n",
    "DATE = 'Oct2-v3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10a7e967-a628-4242-aa7f-22779fec2fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDS = get_IDS(IMG_DIR=IMG_DIR)\n",
    "len(IDS)\n",
    "\n",
    "VERSION_NAME = f'period_clf_bs{BATCH_SIZE}_lr{LR}_{EPOCHS}epochs{SUFFIX}-{len(IDS)}_samples{RUN_NAME_SUFFIX}_blurvae-conv-{DATE}'\n",
    "\n",
    "num_classes = len(TabletPeriodDataset.PERIOD_INDICES)\n",
    "\n",
    "class_weights = torch.load(\"data/class_weights_period.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a84a2b4-0e60-43df-9ec6-cd5edc43e96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chekpoint_path = f'lightning_logs/{VERSION_NAME}/checkpoints/epoch=29-step=407516.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "105fd599-d113-4bc1-b530-9b1526d7bee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sise/mickyfi-group/kapond/AnalysisBySynthesis/VAE_model_tablets_class.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.class_weights = torch.tensor(class_weights).to(device)\n"
     ]
    }
   ],
   "source": [
    "vae_model = VAE.load_from_checkpoint(chekpoint_path,image_channels=1,z_dim=16, lr =1e-5, use_classification_loss=True, num_classes=num_classes,\n",
    "            loss_type=\"weighted\", class_weights=class_weights, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a32a816-9b60-4772-a9b3-d7f43f169520",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encodings_train = pd.read_csv('vae_encodings_and_data/vae_encoding_df_Oct2-v3_w_class_train.csv')\n",
    "df_encodings_test = pd.read_csv('vae_encodings_and_data/vae_encoding_df_Oct2-v3_w_class_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71e3d48f-ab0f-436d-ae43-67c3976fdf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(*args):\n",
    "\n",
    "    vector = np.array([slider.value for slider in sliders])\n",
    "    \n",
    "    if len(vector) == 0:  # Checks if there's no data (vector is empty)\n",
    "        with out:\n",
    "            clear_output(wait=True)\n",
    "            display(Image.new('RGB', (128, 128), color = 'white'))  # Display a blank/white image\n",
    "    else:\n",
    "        out.clear_output(wait=True)\n",
    "    \n",
    "        # Fetch values from sliders\n",
    "        vector = np.array([slider.value for slider in sliders])\n",
    "        \n",
    "        # Convert to tensor and generate image using the model as you provided\n",
    "    \n",
    "        generated_image_tensor = generate_image_from_VAE(vector, vae_model)\n",
    "            \n",
    "        # Assuming the generated image is in the range [0, 1], so we multiply by 255\n",
    "        generated_image_np = (generated_image_tensor.numpy() * 255).astype(np.uint8)\n",
    "    \n",
    "        # Convert to PIL Image and display inside the output widget\n",
    "        image = Image.fromarray(generated_image_np)\n",
    "        with out:\n",
    "            display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3dcb9bd-ad45-4a43-abf7-5e6469464789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c43a8f08d03d4cfcbafde624dab4e5ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Period:', options=('None', 'Achaemenid', 'ED I-II', 'ED IIIa', 'ED IIIb', 'Early Old Bab…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10652d3a52a8494aa8856a206cc77e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Genre:', options=('None', 'Administrative', 'Astronomical', 'Legal', 'Letter', 'Lexical'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03bf0818b5a4ca790ace3041e623d16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import HBox, VBox, Dropdown, Output, FloatSlider\n",
    "\n",
    "# Assuming df_encodings_train is already defined and includes 'Period_Name' and 'Genre_Name'\n",
    "\n",
    "# Dropdown for period selection\n",
    "period_options = ['None'] + sorted(df_encodings_train['Period_Name'].unique().tolist())\n",
    "period_dropdown = Dropdown(options=period_options, value='None', description='Period:')\n",
    "\n",
    "# Dropdown for genre selection\n",
    "genre_options = ['None'] + sorted(df_encodings_train['Genre_Name'].unique().tolist())\n",
    "genre_dropdown = Dropdown(options=genre_options, value='None', description='Genre:')\n",
    "\n",
    "# Container for sliders\n",
    "sliders = []\n",
    "sliders_container = VBox([])  # Initially empty container\n",
    "\n",
    "# Output widget for displaying the image\n",
    "out = Output()\n",
    "\n",
    "# Function to update the output based on dropdown selections\n",
    "def update_output(*args):\n",
    "    period = period_dropdown.value if period_dropdown.value != 'None' else None\n",
    "    genre = genre_dropdown.value if genre_dropdown.value != 'None' else None\n",
    "    \n",
    "    imgs_to_disp_df = df_encodings_train.drop(['Genre', 'Period'], axis=1).copy()\n",
    "    \n",
    "    if period:\n",
    "        imgs_to_disp_df = imgs_to_disp_df[imgs_to_disp_df['Period_Name'] == period]\n",
    "    \n",
    "    if genre:\n",
    "        imgs_to_disp_df = imgs_to_disp_df[imgs_to_disp_df['Genre_Name'] == genre]\n",
    "\n",
    "    if imgs_to_disp_df.empty:\n",
    "        sliders.clear()\n",
    "        sliders_container.children = []  # Clear the display of existing sliders\n",
    "        generate_image()  # This will now display a blank image\n",
    "    else:\n",
    "        sliders.clear()  # Clear existing slider list\n",
    "        initial_vector = imgs_to_disp_df.sample().drop(['Genre_Name', 'Period_Name'], axis=1).iloc[0].values.astype('float32')\n",
    "        \n",
    "        for i, val in enumerate(initial_vector):\n",
    "            slider = FloatSlider(value=val, min=-3, max=3, step=0.01, description=f'Entry {i+1}')\n",
    "            slider.observe(generate_image, 'value')\n",
    "            sliders.append(slider)\n",
    "        \n",
    "        sliders_container.children = [slider for slider in sliders]  # Update the container with new sliders\n",
    "        \n",
    "        generate_image()\n",
    "\n",
    "# Observing dropdowns for changes\n",
    "period_dropdown.observe(update_output, 'value')\n",
    "genre_dropdown.observe(update_output, 'value')\n",
    "\n",
    "# Layout configuration\n",
    "layout_container = HBox([sliders_container, out])\n",
    "\n",
    "# Display widgets\n",
    "display(period_dropdown, genre_dropdown, layout_container)\n",
    "\n",
    "# Initialize\n",
    "update_output()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b4f20f-38d6-4099-8407-f020f6c55d2c",
   "metadata": {},
   "source": [
    "Conclusions?\n",
    "\n",
    "* Entry 1: how wide the tablet is + number of angles shown / rectangular vs round?\n",
    "* Entry 2: is the image placed to the left or not / how big is the centerpiece + thickness of tablet\n",
    "* Entry 3: gap between the angles + is the shape more square?\n",
    "* Entry 4: is the bottom left of the tablet is chipped, and how much + thickness\n",
    "* Entry 5:  is the top left of the tablet is chipped, and how much + narrow side views\n",
    "* Entry 6: how round the tablet is / smaller side centerpiece?\n",
    "* Entry 7: if the picture is taken so that one of the sides is placed on top, or not\n",
    "* Entry 8: how round is the tablet \n",
    "* Entry 9: is the tablet places on the left / right + how narrow the tablet is (is there some shadow ion the right?)\n",
    "* Entry 10: is it one piece showing, or all angles\n",
    "* Entry 11: are there many many displays, or just the 6 sides (e.g. cylinder or multiple fragments) \n",
    "* Entry 12: not so clear - seems like related to the number of fragments / how short the tablet is\n",
    "* Entry 13: not so clear - seems like related to the number of fragments / how wide the tablet is (is there some shadow ion the left?)\n",
    "* Entry 14: not so clear - seems like related to the number of fragments / bottom right of centerpience chipped\n",
    "* Entry 15: not so clear - seems like related to the number of fragments\n",
    "* Entry 16: is it one piece showing, or all angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b98c575-7466-4697-beea-9ac69e53122d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dani_torch",
   "language": "python",
   "name": "dani_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
