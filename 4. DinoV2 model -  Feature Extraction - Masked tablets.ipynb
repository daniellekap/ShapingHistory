{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7f3bdd3-5f5b-41cb-bbf4-891c44446908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize, Lambda\n",
    "from PIL import Image\n",
    "\n",
    "from era_data import TabletPeriodDataset, get_IDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43772357-5ae9-41e9-ab66-3ed17d6f5991",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ee5c6af-e853-44bd-84c6-8f49bd788a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'period_clf_bs8-DinoV2-94936_samples-preprocessed_April20-90-10_train_test'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "SUFFIX = '-DinoV2'\n",
    "DATE = datetime.now().strftime(\"%B%d\")\n",
    "RUN_NAME_SUFFIX = '-preprocessed' \n",
    "IMG_DIR = 'output/images_preprocessed'\n",
    "IDS = get_IDS(IMG_DIR=IMG_DIR)\n",
    "print(len(IDS))\n",
    "VERSION_NAME = f'period_clf_bs{BATCH_SIZE}{SUFFIX}-{len(IDS)}_samples{RUN_NAME_SUFFIX}_{DATE}-90-10_train_test'\n",
    "VERSION_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88268ff4-f056-48d3-86b6-b09838cc35f0",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a77f7cf-9de6-4788-abe9-829e4d1113a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a6db5a7-9562-44bd-9b55-0a9f4f28647a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85442, 9494)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids, test_ids = train_test_split(IDS, test_size=.1, random_state=0)\n",
    "len(train_ids), len(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3646b16-5dc2-4969-b317-9c53c01326a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering 94936 IDS down to provided 85442...\n",
      "Filtering 94936 IDS down to provided 9494...\n"
     ]
    }
   ],
   "source": [
    "ds_train = TabletPeriodDataset(IDS=train_ids, IMG_DIR=IMG_DIR, mask=True)\n",
    "ds_test = TabletPeriodDataset(IDS=test_ids, IMG_DIR=IMG_DIR, mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5547a05b-59e4-4400-a62c-fa43797ba054",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "    Lambda(lambda img: img.convert('RGB')),\n",
    "    Resize((224, 224)),  # Resize image to the input size expected by the model\n",
    "    ToTensor(),  # Convert the image to a tensor\n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize with ImageNet's mean and std\n",
    "])\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = [sample[1] for sample in batch]\n",
    "    labels = [sample[2] for sample in batch]\n",
    "\n",
    "    images = [Image.fromarray(img.numpy()) if isinstance(img, torch.Tensor) else Image.fromarray(img)\n",
    "              for img in images]\n",
    "\n",
    "    # Apply transformations\n",
    "    preprocessed_images = [transform(img) for img in images]\n",
    "\n",
    "    # Stack images and labels into tensors\n",
    "    images_tensor = torch.stack(preprocessed_images)\n",
    "    labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "    images_tensor = images_tensor.to(device)\n",
    "    labels_tensor = labels_tensor.to(device)\n",
    "    \n",
    "    return images_tensor, labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cffe2070-1900-4dd6-adfb-f13d816d8295",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "dl_test = DataLoader(ds_test, batch_size=BATCH_SIZE, collate_fn=collate_fn, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ef28fe1-e0cc-4f67-a366-e7fc97092ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model IDs so we can keep track of what data it was trained on\n",
    "pd.Series(train_ids).to_csv(f'output/clf_ids/period-train-{VERSION_NAME}.csv', index=False, header=None)\n",
    "pd.Series(test_ids).to_csv(f'output/clf_ids/period-test-{VERSION_NAME}.csv', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85c6ad55-ae6d-46e2-80ca-a5c9609ae8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(TabletPeriodDataset.PERIOD_INDICES)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d405bd65-c7fb-403b-889f-8bfcf6d06019",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bdf58b8-933c-4db8-9dcb-33727ea11503",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/kapond/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "/home/kapond/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/home/kapond/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/home/kapond/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DinoVisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 384, kernel_size=(14, 14), stride=(14, 14))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x NestedTensorBlock(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MemEffAttention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "  (head): Identity()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dino = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14', pretrained=True)\n",
    "model_dino.to(device)\n",
    "model_dino.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76bf853a-6ac7-4bef-af45-b1b6d9c1b52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a25a66d-4e45-4d58-aba4-7a5078cf01d0",
   "metadata": {},
   "source": [
    "# Extract and Save Features Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbb27e6-ca04-41d2-ab10-00623db87785",
   "metadata": {},
   "source": [
    "## Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95ba98d4-914b-4ecc-ba88-89514d0e5f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e141d5e7aec4ec59acebb8cfeb640a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10681 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_list = []\n",
    "labels_list = []\n",
    "\n",
    "with torch.no_grad(): \n",
    "    for data, targets in tqdm(dl_train):\n",
    "        images, labels = data.to('cuda'), targets.to('cuda')\n",
    "        features = model_dino(images)\n",
    "        features_list.append(features.cpu()) \n",
    "        labels_list.append(labels.cpu())\n",
    "\n",
    "# Concatenate all features and labels.\n",
    "features_all = torch.cat(features_list, dim=0)\n",
    "labels_all = torch.cat(labels_list, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d04ffd93-d001-4587-af4e-690309b41aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([85442, 384]) torch.Size([85442])\n"
     ]
    }
   ],
   "source": [
    "print(features_all.shape, labels_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65515307-f914-4fa8-b331-d95c3d31edc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_np = features_all.numpy()\n",
    "labels_np = labels_all.numpy()\n",
    "\n",
    "df_features = pd.DataFrame(features_np)\n",
    "\n",
    "# Add labels as a new column to the DataFrame\n",
    "df_features['label'] = labels_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20317ed4-6b59-4b5a-b770-3e4c100bcc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.to_csv('output/dino_v2_train_set_vectors_masked_April20.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaf06f6-4bf1-4859-9f27-6f4cf868a233",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24e3097a-55ca-4579-b547-26605119a34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = pd.read_csv(f'output/clf_ids/period-test-{VERSION_NAME}.csv', header=None, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4914062d-015e-436b-b665-0ea5149a17d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering 94936 IDS down to provided 9494...\n"
     ]
    }
   ],
   "source": [
    "ds_test = TabletPeriodDataset(IDS=test_ids[0].to_list(), IMG_DIR=IMG_DIR, mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36d8e30a-713c-44b3-b1e7-a6a350d39df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_test = DataLoader(ds_test, batch_size=BATCH_SIZE, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55fe4702-6a9b-4e76-8ad1-08d838d8dda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e462ad47a94151986faa752d2c92e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1187 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_list_test = []\n",
    "labels_list_test = []\n",
    "\n",
    "with torch.no_grad(): \n",
    "    for data, targets in tqdm(dl_test):\n",
    "        images, labels = data.to('cuda'), targets.to('cuda')\n",
    "        features = model_dino(images)\n",
    "        features_list_test.append(features.cpu()) \n",
    "        labels_list_test.append(labels.cpu())\n",
    "\n",
    "# Concatenate all features and labels.\n",
    "features_all_test = torch.cat(features_list_test, dim=0)\n",
    "labels_all_test = torch.cat(labels_list_test, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76bcfa7d-7ef0-40db-ad4b-56f6216c4bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_np_test = features_all_test.numpy()\n",
    "labels_np_test = labels_all_test.numpy()\n",
    "\n",
    "df_features_test = pd.DataFrame(features_np_test)\n",
    "\n",
    "df_features_test['label'] = labels_np_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b57044e2-3b3f-41ca-b9a6-7b9161993bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_test.to_csv('output/dino_v2_test_set_vectors_masked_April20.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0d3778-fdcd-416d-a604-4aab7019d84b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dani_torch",
   "language": "python",
   "name": "dani_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
